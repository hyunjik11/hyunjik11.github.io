
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<style type="text/css" media="all">
body {font-family: 'Droid Sans', helvetica,Arial,sans-serif;}
a:link, a:visited, a:active {text-decoration:none}
div.container{width:80%; margin:2%; line-height:140%;}
div.right{float:right;width:200px; margin:1em; padding:1em;}
div.content{margin-left:4%; padding:1em;}
</style>

<title>Hyunjik Kim</title>
<meta name="description" content="Academic page of Hyunjik Kim. Research on machine learning, scalable inference, and automated modeling.">
<meta name="keywords" content="Automatic machine learning, Gaussian processes, Bayesian machine learning">
<meta name="resource-type" content="document">
<meta name="distribution" content="global">
<meta http-equiv="Content-Style-Type" content="text/css">

<script type="text/javascript" async="" src="www.google-analytics.com/ga.js"></script>
<script type="text/javascript">
    function trackOutboundLink(link, category, action) { 
        try { 
        _gaq.push(['_trackEvent', category , action]); 
        } catch(err){}
    }
</script>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-8635368-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

<style type="text/css">
  div.foo p {
margin-bottom:0.0em; 
margin-top:0.0em;
}
</style>

</head>

<body>
<br>
<div class="container">
<!--<div class="right"><img alt="" width="200px" src="./pictures/profile5.png"></div>-->
<div class="right"><img alt="" width="250px" src="./pictures/profile_head.jpg"></div>
<div class="content">
<h1 style="text-align: left;">Hyunjik Kim</h1>

<b><font size="4">
<a href="#preprints"      onClick="_gaq.push(['_trackEvent', 'withinpage', 'preprints', 'textlink']);">Preprints</a>
<!--| <a href="#courses"      onclick="_gaq.push(['_trackEvent', 'withinpage', 'courses', 'textlink']);">Courses</a>-->
| <a href="#publications" onclick="_gaq.push(['_trackEvent', 'withinpage', 'publications', 'textlink']);">Publications</a>
</font></b>

<!-- <img alt="" src="./pictures/text.png"> -->
<br><br>

<p>I'm a fourth year PhD student in machine learning at the <a href="http://www.ox.ac.uk/">University of Oxford</a>, supervised by <a href="http://www.stats.ox.ac.uk/~teh/">Prof. Yee Whye Teh</a> in the <a href="http://csml.stats.ox.ac.uk/">Machine Learning group</a> at the <a href="http://stats.ox.ac.uk/"> Department of Statistics</a>. 
I also spend two days a week at <a href="https://deepmind.com/">DeepMind</a> at the Google London office as a research scientist. </p>
<p>My research interests lie at the intersection of Bayesian Machine Learning and Deep Learning, especially interpretable models that arise in this intersection.
In particular, I'm interested in unsupervised/semi-supervised representation learning (e.g. disentangling) and learning stochastic processes via Deep Learning methods. Other (related) areas of interest include generative models of image/video and meta-learning.
Previously, I have worked on scaling up inference for Gaussian processes, in particular on regression models for collaborative filtering that are motivated by a scalable approximation to a GP, 
as well as a method for scaling up the compositional kernel search used by the <a href="https://www.automaticstatistician.com/index/">Automatic Statistician</a> via variational sparse GP methods.
 </p>
<p> Before my PhD, I studied Mathematics at the <a href="https://www.cam.ac.uk/">University of Cambridge</a>, from which I obtained B.A. and M.Math. degrees. 
I spent a summer at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/">Microsoft Research, Cambridge</a> as a research intern, and worked on collaborative filtering. 
I spent last summer interning at <a href="https://deepmind.com/">DeepMind</a> working on unsupervised learning of disentangled representations.

<p><a href="./cv/CV_Hyunjik_Kim.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'resume', 'pdf']);">Curriculum Vitae</a> (last updated: Dec 2018)</p>
<p><a href="https://scholar.google.co.uk/citations?user=vxU3Zk4AAAAJ&hl=en&oi=ao">Google scholar page</a></p>
	
<p> 
E-mail: <a href="mailto:hkim@stats.ox.ac.uk">hkim@stats.ox.ac.uk</a>
</p>

<div class="foo">
	
<!-- Recent -->
	
<H2><a id="recent">Recent</a></H2>
<table border="0" cellspacing="4" cellpadding="2">

<tr>
<td valign="top">
  <a href="http://bayesiandeeplearning.org/2018/papers/28.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'anp', 'pdf' ]); ">
  </a>
</td>
<td valign="top">
  <b>Attentive Neural Processes</b>
<p>
<em>Abstract:</em> Neural Processes (NPs) (Garnelo et al., 2018a,b) approach regression by learning
to map a context set of observed input-output pairs to a distribution over regression
functions. Each function models the distribution of the output given an input, conditioned
on the context. NPs have the benefit of fitting observed data efficiently
with linear complexity in the number of context input-output pairs, and can learn
a wide family of conditional distributions; they learn predictive distributions conditioned
on context sets of arbitrary size. Nonetheless, we show that NPs suffer a
fundamental drawback of underfitting, giving inaccurate predictions at the inputs
of the observed data they condition on. We address this issue by incorporating
attention into NPs, allowing each input location to attend to the relevant context
points for the prediction. We show that this greatly improves the accuracy of predictions,
results in noticeably faster training, and expands the range of functions
that can be modelled.

</p>
  <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Hyunjik');">Hyunjik Kim</a>,
  <a href="https://www.cs.toronto.edu/~amnih/" onclick="trackOutboundLink(this, 'outbound', 'Andriy');">Andriy Mnih</a>,
  <a href="https://jonathan-schwarz.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Jonathan');">Jonathan Schwarz</a>,
  <a href="https://www.doc.ic.ac.uk/~mg4413/" onclick="trackOutboundLink(this, 'outbound', 'Marta');">Marta Garnelo</a>,
  <a href="http://arkitus.com/research/" onclick="trackOutboundLink(this, 'outbound', 'Ali Eslami');">Ali Eslami</a>,
  <a href="http://www.cs.huji.ac.il/~danrsm/" onclick="trackOutboundLink(this, 'outbound', 'Dan Rosenbaum');">Dan Rosenbaum</a>,
  <a href="https://ai.google/research/people/OriolVinyals" onclick="trackOutboundLink(this, 'outbound', 'Oriol Vinyals');">Oriol Vinyals</a>,
  <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
<br>
<em>Bayesian Deep Learning Workshop, NeurIPS 2018. </em> Contributed Talk.<br>
<a href="http://bayesiandeeplearning.org/2018/papers/28.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'anp', 'pdf' ]);">pdf</a>
<br>
	<em><b>ICLR 2019.</b></em> <br>
  <a href="https://openreview.net/pdf?id=SkE6PjC9KX" onclick="_gaq.push(['_trackEvent', 'downloads', 'anp', 'pdf' ]);">pdf</a>
  | <a href="./papers/bibtex/anp.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'anp', 'bibtex' ]);">bibtex</a> 
  | <a href="https://openreview.net/forum?id=SkE6PjC9KX" onclick="_gaq.push(['_trackEvent', 'downloads', 'anp', 'openreview' ]);">openreview</a> 
<br>
</td></tr>
	
<tr>
<td valign="top">
  <a href="https://arxiv.org/pdf/1806.01794" onclick="_gaq.push(['_trackEvent', 'downloads', 'sqair', 'pdf' ]); ">
  </a>
</td>
<td valign="top">
  <b>Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects</b>
<p>
<em>Abstract:</em> We present Sequential Attend, Infer, Repeat (SQAIR), an interpretable deep generative model for videos of moving objects. 
	It can reliably discover and track objects throughout the sequence of frames, 
	and can also generate future frames conditioning on the current frame, 
	thereby simulating expected motion of objects. 
	This is achieved by explicitly encoding object presence, locations and appearances in the latent variables of the model. 
	SQAIR retains all strengths of its predecessor, Attend, Infer, Repeat (AIR, Eslami et. al., 2016), 
	including learning in an unsupervised manner, and addresses its shortcomings. 
	We use a moving multi-MNIST dataset to show limitations of AIR in detecting overlapping or partially occluded objects,
	and show how SQAIR overcomes them by leveraging temporal consistency of objects. 
	Finally, we also apply SQAIR to real-world pedestrian CCTV data, 
	where it learns to reliably detect, track and generate walking pedestrians with no supervision.

</p>
  <a href="http://akosiorek.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Adam');">Adam Kosiorek</a>,
  <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Hyunjik');">Hyunjik Kim</a>,
  <a href="http://ori.ox.ac.uk/mrg_people/ingmar-posner/" onclick="trackOutboundLink(this, 'outbound', 'Ingmar');">Ingmar Posner</a>,
  <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
<br>
<em><b>NeurIPS 2018. </em> Spotlight.</b><br>
  <a href="https://arxiv.org/abs/1806.01794" onclick="_gaq.push(['_trackEvent', 'downloads', 'sqair', 'pdf' ]);">pdf</a>
  | <a href="./papers/bibtex/sqair.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'sqair', 'bibtex' ]);">bibtex</a>
<br>
</td></tr>	
	
</table>			

<!-- Publications -->
	
<p>
</p><h2><a id="publications">Publications</a></h2>
<table border="0" cellspacing="4" cellpadding="2"><tbody>

<tr>
<td valign="top">
  <a href="https://arxiv.org/pdf/1802.05983.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'disent', 'pdf' ]); ">
  </a>
</td>
<td valign="top">
  <b>Disentangling by Factorising</b>
<p>
<em>Abstract:</em> We define and address the problem of unsupervised learning of disentangled representations on data generated from independent factors of variation. We propose FactorVAE, a method that disentangles by encouraging the distribution of representations to be factorial and hence independent across the dimensions. We show that it improves upon Î²-VAE by providing a better trade-off between disentanglement and reconstruction quality. 
	Moreover, we highlight the problems of a commonly used disentanglement metric and introduce a new metric that does not suffer from them.</p>
  <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Hyunjik');">Hyunjik Kim</a>,
  <a href="https://www.cs.toronto.edu/~amnih/" onclick="trackOutboundLink(this, 'outbound', 'Andriy');">Andriy Mnih</a>
<br>
<em>Learning Disentangled Representations: From Perception to Control Workshop, NIPS 2017.</em> Spotlight Talk. <br>
  <a href="https://drive.google.com/open?id=0Bwy4Nlx78QCCQzJldThTUlJfal9ha0l3bThRZXY3RmFCUVB3" onclick="_gaq.push(['_trackEvent', 'downloads', 'factorvae', 'pdf' ]);">pdf</a>
<br>
<em><b>ICML 2018</b></em> <br>
  <a href="https://arxiv.org/pdf/1802.05983.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'disent', 'pdf' ]);">pdf</a>
  | <a href="./papers/bibtex/disentangling_by_factorising.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'disent', 'bibtex' ]);">bibtex</a>
<br>	
</td></tr>
	
<tr>
<td valign="top">
  <a href="http://www.jmlr.org/proceedings/papers/v64/kim_scalable_2016.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'autograd', 'pdf' ]); ">
  </a>
</td>
<td valign="top">
  <b>Scaling up the Automatic Statistician: Scalable Structure Discovery using Gaussian Processes</b>
<p>
<em>Abstract:</em> Automating statistical modelling is a challenging problem in artificial intelligence. 
	The Automatic Statistician takes a first step in this direction, by employing a kernel search algorithm with Gaussian Processes (GP) to provide interpretable statistical models for regression problems. 
	However this does not scale due to its O(N^3) running time for the model selection. 
	We propose Scalable Kernel Composition (SKC), a scalable kernel search algorithm that extends the Automatic Statistician to bigger data sets. 
	In doing so, we derive a cheap upper bound on the GP marginal likelihood that sandwiches the marginal likelihood with the variational lower bound. 
	We show that the upper bound is significantly tighter than the lower bound and thus useful for model selection.</p>
  <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Hyunjik');">Hyunjik Kim</a>,
  <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
<br>	
<em>AutoML 2016, Journal of Machine Learning Research Workshop and Conference Proceedings.</em> <br>
	<em>Practical Bayesian Nonparametrics Workshop, NIPS 2016.</em> Oral &amp; Travel Award. <br>
  <a href="http://www.jmlr.org/proceedings/papers/v64/kim_scalable_2016.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'ssdgp', 'pdf' ]);">pdf</a>
<br>
<em><b>AISTATS 2018.</em> Oral.</b><br>
  <a href="https://arxiv.org/pdf/1706.02524" onclick="_gaq.push(['_trackEvent', 'downloads', 'tuckergp', 'pdf' ]);">pdf</a>
  | <a href="./papers/bibtex/ssdgp.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'tuckergp', 'bibtex' ]);">bibtex</a>
<br>
</td></tr>
<tr><td height="10px"></td></tr>
</tbody></table>
	
<!-- Preprints -->
<H2><a id="preprints">Preprints</a></H2>
<table border="0" cellspacing="4" cellpadding="2">

<tr>
<td valign="top">
  <a href="https://arxiv.org/pdf/1605.07025v2.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'tuckergp', 'pdf' ]); ">
  </a>
</td>
<td valign="top">
  <b>Collaborative Filtering with Side Information: a Gaussian Process Perspective</b>
<p>
<em>Abstract:</em> We tackle the problem of collaborative filtering (CF) with side information,
	through the lens of Gaussian Process (GP) regression. Driven by the idea of using the kernel 
	to explicitly model user-item similarities, we formulate the GP in a way that allows the 
	incorporation of low-rank matrix factorisation, arriving at our model, the Tucker Gaussian Process (TGP). 
	Consequently, TGP generalises classical Bayesian matrix factorisation models, 
	and goes beyond them to give a natural and elegant method for incorporating side information, 
	giving enhanced predictive performance for CF problems. 
	Moreover we show that it is a novel model for regression, 
	especially well-suited to grid-structured data and problems 
	where the dependence on covariates is close to being separable.
</p>
  <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Hyunjik');">Hyunjik Kim</a>,
  Xiaoyu Lu,
  <a href="http://sethrf.com/" onclick="trackOutboundLink(this, 'outbound', 'Seth');">Seth Flaxman</a>,
  <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
<br>
<em>ArXiv</em>, 2016<br>
  <a href="https://arxiv.org/pdf/1605.07025" onclick="_gaq.push(['_trackEvent', 'downloads', 'tuckergp', 'pdf' ]);">pdf</a>
  | <a href="./papers/bibtex/tuckergp.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'tuckergp', 'bibtex' ]);">bibtex</a>
<br>
</td></tr>
<tr><td height="10px"></td></tr>
</table>

<!-- Preprints -->
<H2><a id="public engagement">Public Engagement</a></H2>
<table border="0" cellspacing="4" cellpadding="2">	
<tr>
<td valign="top">
  <a href="http://www.oxfordsparks.ox.ac.uk/content/what-machine-learning" onclick="_gaq.push(['_trackEvent', 'downloads', 'oxfordsparks', 'pdf' ]); ">
  </a>
</td>
<td valign="top">
  <br>
  <b>Introducing Machine Learning to the Public</b>
<p>
I helped create a cute two-minute animation that introduces machine learning to the general public, along with friends at Oxford.
Check it out below!
<br> <br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/f_uwKZIAeM0" frameborder="0" allowfullscreen></iframe>
<br><br>
Further details can be found <a href="http://www.oxfordsparks.ox.ac.uk/content/what-machine-learning" onclick="_gaq.push(['_trackEvent', 'downloads', 'oxfordsparks']);">here</a>
</p>
</td></tr>	

</div>
</div>
</div>

</body></html>
